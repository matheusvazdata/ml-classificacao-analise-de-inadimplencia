# ğŸ“Œ Projeto: ClassificaÃ§Ã£o de Inadimplentes com Machine Learning

Este projeto tem como objetivo entender os fatores que levam Ã  **inadimplÃªncia de clientes** e desenvolver um **modelo preditivo** para auxiliar instituiÃ§Ãµes financeiras na gestÃ£o de crÃ©dito. A abordagem inclui desde a anÃ¡lise exploratÃ³ria atÃ© a otimizaÃ§Ã£o do modelo, utilizando tÃ©cnicas avanÃ§adas de Machine Learning e Engenharia de Features.

## ğŸ¯ Objetivos

- **Analisar fatores** que influenciam a inadimplÃªncia.
- **Identificar variÃ¡veis relevantes** para prever o comportamento financeiro dos clientes.
- **Criar e otimizar um modelo de classificaÃ§Ã£o**, focando na reduÃ§Ã£o de falsos negativos.
- **Gerar insights acionÃ¡veis** para aprimorar a gestÃ£o de risco financeiro.

## ğŸ“‚ Estrutura do Projeto

```
â”œâ”€â”€ ğŸ“‚ data                                          # Backup do dataset
â”œâ”€â”€ Projeto-ML-Classificacao-de-Inadimplentes.ipynb  # Notebook principal com todo o pipeline
â”œâ”€â”€ README.md                                        # Este arquivo
```

## ğŸ”§ Tecnologias Utilizadas

- **Linguagem**: Python
- **Bibliotecas**: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `XGBoost`, `imbalanced-learn`
- **Ferramentas**: Google Colab, Google Cloud Storage, GitHub
- **TÃ©cnicas Aplicadas**: **SMOTE**, **Feature Engineering**, **PCA**, **GridSearchCV**

## ğŸ“Š Etapas do Projeto

1. **AquisiÃ§Ã£o de Dados**  
   - ImportaÃ§Ã£o de dataset de clientes.
   - Tratamento de valores ausentes e inconsistÃªncias.

2. **AnÃ¡lise ExploratÃ³ria (EDA)**  
   - IdentificaÃ§Ã£o de padrÃµes entre clientes adimplentes e inadimplentes.  
   - VisualizaÃ§Ã£o das principais variÃ¡veis categÃ³ricas e numÃ©ricas.  

3. **Engenharia de Features**  
   - **CriaÃ§Ã£o de novas variÃ¡veis** como taxa de utilizaÃ§Ã£o de crÃ©dito, mÃ©dia de transaÃ§Ãµes e intensidade de interaÃ§Ãµes.  
   - **TransformaÃ§Ãµes**: Label Encoding, One-Hot Encoding e normalizaÃ§Ã£o dos dados.  

4. **Modelagem e Treinamento**  
   - Teste de modelos iniciais: **RegressÃ£o LogÃ­stica, Ãrvore de DecisÃ£o, Random Forest e XGBoost**.  
   - AplicaÃ§Ã£o de **SMOTE** para balanceamento das classes.  
   - **OtimizaÃ§Ã£o do XGBoost** com GridSearchCV.  

5. **AvaliaÃ§Ã£o e InterpretaÃ§Ã£o**  
   - **MÃ©tricas de performance**: Recall, AUC-ROC, F1-Score.  
   - **AnÃ¡lise de matriz de confusÃ£o** para entender erros do modelo.  
   - **ImportÃ¢ncia das features** para entender os principais fatores de inadimplÃªncia.  

## ğŸ“ˆ Principais Resultados

- O **XGBoost otimizado** apresentou os melhores resultados, equilibrando recall e precisÃ£o.
- A **quantidade de transaÃ§Ãµes** e a **mÃ©dia do valor transacionado** foram variÃ¡veis cruciais para a previsÃ£o.
- Clientes com **maior tempo de inatividade** e **menor uso do crÃ©dito disponÃ­vel** tÃªm maior risco de inadimplÃªncia.

## ğŸš€ PrÃ³ximos Passos

- ImplementaÃ§Ã£o de **LightGBM e CatBoost** para comparaÃ§Ã£o de desempenho.  
- Refinamento do **threshold de decisÃ£o** para reduzir falsos negativos.  
- ExploraÃ§Ã£o de **tÃ©cnicas de Explainable AI (SHAP/LIME)** para interpretar melhor as previsÃµes.  

## ğŸ¤ ContribuiÃ§Ãµes

Se quiser contribuir, sinta-se Ã  vontade para abrir uma **issue** ou enviar um **pull request**. Qualquer sugestÃ£o para melhorias serÃ¡ bem-vinda!

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**. Consulte o arquivo LICENSE para mais detalhes.
